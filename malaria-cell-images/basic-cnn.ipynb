{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 말라리아 셀 이미지\n",
    "* 말라리아 스크리너 연구 활동의 분할된 세포의 얇은 혈액 도말 슬라이드 이미지\n",
    "* 리소스가 제한된 지역에서 현미경 전문가의 부담을 줄이고 진단 정확도를 개선하기 위해 NLM(National Library of Medicine)의 일부인 Lister Hill National Center for Biomedical Communications(LHNCBC)의 연구원들은 모바일 애플리케이션을 개발\n",
    "* 방글라데시 치타공 의과대학 병원에서 150명의 P. falciparum 감염자와 50명의 건강한 환자의 Giemsa 염색 얇은 혈액 도말 슬라이드를 수집하고 사진을 촬영\n",
    "* 적혈구를 감지하고 분할하기 위해 레벨 세트 기반 알고리즘을 적용\n",
    "\n",
    "### 이미지 출처 \n",
    "* [LHNCBC Full Download List](https://lhncbc.nlm.nih.gov/LHC-downloads/downloads.html#malaria-datasets)\n",
    "* [Malaria Cell Images Dataset | Kaggle](https://www.kaggle.com/iarunava/cell-images-for-detecting-malaria)\n",
    "* 관련 논문 : [Performance evaluation of deep neural ensembles toward malaria parasite detection in thin-blood smear images [PeerJ]](https://peerj.com/articles/6977/)\n",
    "* 해당 논문의 github : [sivaramakrishnan-rajaraman/Deep-Neural-Ensembles-toward-Malaria-Parasite-Detection-in-Thin-Blood-Smear-Images: This study evaluates the performance of custom and pretrained CNNs and construct an optimal model ensemble toward the challenge of classifying parasitized and normal cells in thin blood smear images. The results obtained are encouraging and superior to the state-of-the-art.](https://github.com/sivaramakrishnan-rajaraman/Deep-Neural-Ensembles-toward-Malaria-Parasite-Detection-in-Thin-Blood-Smear-Images)\n",
    "\n",
    "<img src=\"https://i.imgur.com/okCbMzc.png\" width=\"400\">\n",
    "\n",
    "## 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 폴더 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 다운로드\n",
    "# !wget https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images 폴더에 다운로드 받은 파일 압축 해제하기\n",
    "# !unzip cell_images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for root, dirs, files in os.walk(\"./cell_images/\"):\n",
    "    print(root, dirs, len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일부 이미지 미리보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "upics = glob.glob('./cell_images/Uninfected/*.png')\n",
    "apics = glob.glob('./cell_images/Parasitized/*.png')\n",
    "len(upics), upics[0], len(apics), apics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upics[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upics[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "labels = \"Uninfected\"\n",
    "for i, images in enumerate(upics[:9]):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    img = cv2.imread(images)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'{labels} {img.shape}')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "labels = \"Infected\"\n",
    "for i, images in enumerate(apics[:9]):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    img = cv2.imread(images)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'{labels} {img.shape}')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 나누기\n",
    "* 학습, 검증 세트를 나눕니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# validation_split 값을 통해 학습:검증 비율을 8:2 로 나눕니다.\n",
    "datagen = ImageDataGenerator(rescale=1/255.0, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 사이즈 설정\n",
    "* 이미지의 사이즈가 불규칙하면 학습을 할 수 없기 때문에 리사이즈할 크기를 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 64\n",
    "height = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 세트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatagen = datagen.flow_from_directory(directory = 'cell_images/',\n",
    "                                           target_size = (height, width),\n",
    "                                           class_mode = 'binary',\n",
    "                                           batch_size = 64,\n",
    "                                           subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatagen.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatagen.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검증 세트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valDatagen = datagen.flow_from_directory(directory = 'cell_images/',\n",
    "                                         target_size =(height, width),\n",
    "                                         class_mode = 'binary',\n",
    "                                         batch_size = 64,\n",
    "                                         subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 레이어 설정\n",
    "\n",
    "<img src=\"https://d2l.ai/_images/lenet.svg\">\n",
    "* 이미지 출처 : https://d2l.ai/chapter_convolutional-neural-networks/lenet.html\n",
    "\n",
    "* [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)와 [MaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) 층을 쌓는 일반적인 패턴으로 합성곱 층을 정의합니다.\n",
    " \n",
    "* CNN은 배치(batch) 크기를 제외하고 (이미지 높이, 이미지 너비, 컬러 채널) 크기의 텐서(tensor)를 입력으로 받습니다. \n",
    "* 컬러 이미지는 (R,G,B) 세 개의 채널을 가집니다. (흑백 이미지는 채널이 하나 입니다.)\n",
    "\n",
    "* 컨볼루션 과정 참고 : https://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "<img src=\"https://indoml.files.wordpress.com/2018/03/one-convolution-layer1.png\" width=\"500\">\n",
    "\n",
    "* filters : 컨볼루션 필터의 수 >> 필터 수 = 특징맵 수\n",
    "* kernel_size : 컨볼루션 커널의 (행, 열)  >> 필터 사이즈\n",
    "* padding : 경계 처리 방법\n",
    "    * ‘valid’ : 유효한 영역만 출력이 됩니다. 따라서 출력 이미지 사이즈는 입력 사이즈보다 작습니다.\n",
    "    * ‘same’ : 출력 이미지 사이즈가 입력 이미지 사이즈와 동일합니다.\n",
    "* input_shape : 모델에서 첫 레이어에서 정의 (height, width, channels)\n",
    "*  activation : 활성화 함수 설정\n",
    "    * ‘linear’ : 디폴트 값, 입력뉴런과 가중치로 계산된 결과값이 그대로 출력\n",
    "    * ‘relu’ : rectifier 함수, 은닉층에 주로 사용\n",
    "    * ‘sigmoid’ : 시그모이드 함수, 이진 분류 문제에서 출력층에 주로 사용\n",
    "    * ‘softmax’ : 소프트맥스 함수, 다중 클래스 분류 문제에서 출력층에 주로 사용\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Hanli-Wang-2/publication/300020038/figure/fig2/AS:404961465782275@1473561745471/Toy-example-illustrating-the-drawbacks-of-max-pooling-and-average-pooling.png\">\n",
    "\n",
    "* Dense Layer: \n",
    "    * 밀집 연결(densely-connected) 또는 완전 연결(fully-connected) 층이라고 부릅니다. \n",
    "    * 첫 번째 Dense 층은 128개의 노드(또는 뉴런)를 가집니다. \n",
    "    * 마지막 층은 출력층 입니다.\n",
    "        * 소프트맥스 일 때 : 2개의 노드의 소프트맥스(softmax) 층입니다. 이 층은 2개의 확률을 반환하고 반환된 값의 전체 합은 1입니다. \n",
    "        * 각 노드는 현재 이미지가 2개 클래스 중 하나에 속할 확률을 출력합니다.\n",
    "        * 시그모이드 일 때 : 둘 중 하나를 예측할 때 1개의 출력값을 출력합니다. 확률을 받아 임계값 기준으로 True, False로 나눕니다.\n",
    "    \n",
    "    \n",
    "* 출력층 :\n",
    "    * 예측 값이 n개 일 때 :  tf.keras.layers.Dense(n, activation='softmax')\n",
    "    * 예측 값이 둘 중 하나일 때 : tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "\n",
    "* 합성곱 신경망 : https://www.tensorflow.org/tutorials/images/cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(height, width, 3)))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model 을 통한 레이어 시각화\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 컴파일\n",
    "\n",
    "\n",
    "모델을 훈련하기 전에 필요한 몇 가지 설정이 모델 컴파일 단계에서 추가됩니다:\n",
    "\n",
    "* 옵티마이저(Optimizer) - 데이터와 손실 함수를 바탕으로 모델의 업데이트 방법을 결정합니다.\n",
    "* 지표(Metrics) - 훈련 단계와 테스트 단계를 모니터링하기 위해 사용합니다. 다음 예에서는 올바르게 분류된 이미지의 비율인 정확도를 사용합니다.\n",
    "\n",
    "\n",
    "* 손실 함수(Loss function) - 훈련 하는 동안 모델의 오차를 측정합니다. 모델의 학습이 올바른 방향으로 향하도록 이 함수를 최소화해야 합니다. 최적의 가중치를 찾도록 해야함\n",
    "    * 회귀  : MSE, MAE\n",
    "    * 분류 : \n",
    "        * 바이너리(예측할 값의 종류가 둘 중 하나) : \n",
    "            * binary_crossentropy\n",
    "        * 멀티클래스(예측할 값의 종류가 2개 이상) : \n",
    "            * categorical_crossentropy(one-hot형태의 클래스 예: [0, 1, 0, 0])\n",
    "            * sparse_categorical_crossentropy(정답값이 0, 1, 2, 3, 4 와 같은 형태일 때)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습\n",
    "\n",
    "* 배치(batch): 모델 학습에 한 번에 입력할 데이터셋\n",
    "* 에폭(epoch): 모델 학습시 전체 데이터를 학습한 횟 수\n",
    "* 스텝(step): (모델 학습의 경우) 하나의 배치를 학습한 횟 수\n",
    "* EarlyStopping: 성능이 더 이상 좋아지지 않으면 학습을 중지\n",
    "    * early_stop = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(trainDatagen,\n",
    "                    steps_per_epoch = len(trainDatagen),\n",
    "                    epochs = 10,\n",
    "                    validation_data = valDatagen,\n",
    "                    validation_steps=len(valDatagen),\n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist = pd.DataFrame(history.history)\n",
    "df_hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist[[\"accuracy\", \"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
